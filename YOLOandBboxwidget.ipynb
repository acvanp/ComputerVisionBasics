{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ipyannotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ipyannotations.images import BoxAnnotator\n",
    "#box_widget = BoxAnnotator(options=[\"decedent_name\"])\n",
    "#box_widget.display(\"Capture1.png\")\n",
    "#box_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipywidgets\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "#!jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "#%pip install jupyter_bbox_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_bbox_widget import BBoxWidget\n",
    "import os\n",
    "import base64\n",
    "import ipywidgets as widgets\n",
    "cwd = os.getcwd()\n",
    "\n",
    "state = 'Florida'\n",
    "path = cwd + '/' + state + '/'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "mypath = cwd + '/' + state + '/'\n",
    "filenames = next(walk(mypath), (None, None, []))[2]  # [] if no file\n",
    "filenames = [i for i in filenames if i.endswith('pdf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "randomsample = random.sample(range(len(filenames)), 200)\n",
    "pdfsample = [filenames[i] for i in randomsample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(state, doc):\n",
    "    path = cwd + '/' + state + '/'\n",
    "    pdf_pages = convert_from_path(path + doc,300)\n",
    "    c=0\n",
    "    image_file_list = []\n",
    "    for page_enumeration, page in enumerate(pdf_pages, start=1):\n",
    "        # enumerate() \"counts\" the pages for us.\n",
    "        # Create a file name to store the image\n",
    "        filename = r\"{}.jpg\".format(doc.split('.pdf')[0])\n",
    "        print(filename)\n",
    "        # Declaring filename for each page of PDF as JPG\n",
    "        # Save the image of the page in system\n",
    "        page.save(cwd + '/FloridaYoloImages/' + filename, \"JPEG\")\n",
    "        image_file_list.append(cwd + '/FloridaYoloImages/' + filename)\n",
    "        return image_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from PIL import Image as PILImage\n",
    "import pytesseract\n",
    "from wand.image import Image as wi\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "for pdf_fname in pdfsample: imlist = ocr(state, pdf_fname)\n",
    "imlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pdf2image\n",
    "from PIL import Image\n",
    "mypath = cwd + '/FloridaYoloImages/' \n",
    "filenames = next(walk(mypath), (None, None, []))[2]  # [] if no file\n",
    "\n",
    "size = 1200, 1554\n",
    "\n",
    "for infile in filenames:\n",
    "    outfile = mypath + infile\n",
    "    im = Image.open(mypath + infile)\n",
    "    im.thumbnail(size, Image.Resampling.LANCZOS)\n",
    "    im.save(outfile, \"JPEG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = mypath\n",
    "files = sorted(os.listdir(path))\n",
    "print(files)\n",
    "files = [i for i in files if i.lower()[-3:] in ['png', 'jpg']]\n",
    "print(files)         \n",
    "annotations = {}\n",
    "annotations_path = 'annotations.json'\n",
    "\n",
    "def encode_image(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "    encoded = str(base64.b64encode(image_bytes), 'utf-8')\n",
    "    print('encode image works')\n",
    "    return \"data:image/jpg;base64,\"+encoded\n",
    "     \n",
    "    \n",
    "w_progress = widgets.IntProgress(value=0, max=len(files), description='Progress')\n",
    "# the bbox widget\n",
    "w_bbox = BBoxWidget(\n",
    "    image= encode_image(path + files[0]),\n",
    "    classes=['class1',],\n",
    ")\n",
    "@w_bbox.on_skip\n",
    "def skip():\n",
    "    w_progress.value += 1\n",
    "    # open new image in the widget\n",
    "    image_file = files[w_progress.value]\n",
    "    w_bbox.image = encode_image(os.path.join(path, image_file))\n",
    "    # here we assign an empty list to bboxes but \n",
    "    # we could also run a detection model on the file\n",
    "    # and use its output for creating inital bboxes\n",
    "    w_bbox.bboxes = [] \n",
    "\n",
    "# when Submit button is pressed we save current annotations\n",
    "# and then move on to the next file\n",
    "@w_bbox.on_submit\n",
    "def submit():\n",
    "    image_file = files[w_progress.value]\n",
    "    # save annotations for current image\n",
    "    annotations[image_file] = w_bbox.bboxes\n",
    "    with open(annotations_path, 'w') as f:\n",
    "        json.dump(annotations, f, indent=4)\n",
    "    # move on to the next file\n",
    "    skip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate bounding boxes here\n",
    "#from jupyter_bbox_widget import BBoxWidget\n",
    "w_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(annotations), annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\"\"\"\n",
    "with open('annotationsNov25.json', 'w') as fp:\n",
    "    json.dump(annotations, fp)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotations = json.load('annotations1.json')\n",
    "\n",
    "with open('annotationsNov25.json') as f:\n",
    "    annotations = json.load(f)\n",
    "    print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_bbox.bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "int_slider = widgets.IntSlider(max=10, value=5)\n",
    "int_slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/ultralytics/yolov5  # clone\n",
    "#cd yolov5\n",
    "%pip install -qr yolov5/requirements.txt comet_ml  # install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import utils\n",
    "#display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import pandas as pd\n",
    "import ast\n",
    "!mkdir /mnt/batch/tasks/shared/LS_root/mounts/clusters/avanplatinga-gpu-nv6/code/Users/AVanPlantinga/OCR/yolov5/images\n",
    "!mkdir /mnt/batch/tasks/shared/LS_root/mounts/clusters/avanplatinga-gpu-nv6/code/Users/AVanPlantinga/OCR/yolov5/labels\n",
    "\n",
    "path = r'yolov5/labels/'\n",
    "\n",
    "annot_dict = annotations\n",
    "cc=0\n",
    "for k in list(annotations.keys()):\n",
    "    a = annotations[k][0]\n",
    "    #print(a)\n",
    "    im = k.split('.')[0]\n",
    "    t = ''\n",
    "    try: f = open(path + \"{}.txt\".format(im), \"x\")\n",
    "    except: pass\n",
    "    f.close()\n",
    "    f = open(path + \"{}.txt\".format(im), \"a\")\n",
    "    t += '0 {0} {1} {2} {3} \\n'.format(a['x']/1200, a['y']/1554, a['width']/1200, a['height']/1554)\n",
    "    #print(f)\n",
    "    f.write('0 {0} {1} {2} {3}'.format(a['x']/1200, a['y']/1554, a['width']/1200, a['height']/1554))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Select YOLOv5 🚀 logger {run: 'auto'}\n",
    "logger = 'Comet' #@param ['Comet', 'ClearML', 'TensorBoard']\n",
    "\n",
    "if logger == 'Comet':\n",
    "  %pip install -q comet_ml\n",
    "  import comet_ml; comet_ml.init()\n",
    "elif logger == 'ClearML':\n",
    "  %pip install -q clearml\n",
    "  import clearml; clearml.browser_login()\n",
    "elif logger == 'TensorBoard':\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir runs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "fnamepath = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/avanplatinga-gpu-nv6/code/Users/AVanPlantinga/OCR/yolov5/images/'\n",
    "f = open(fnamepath + \"filenames.txt\", \"w\")\n",
    "f.close()\n",
    "f = open(fnamepath + \"filenames.txt\", \"a\")\n",
    "cc=0\n",
    "for i in list(annotations.keys()):\n",
    "    impath = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/avanplatinga-gpu-nv6/code/Users/AVanPlantinga/OCR/FloridaYoloImages/' + i\n",
    "    os.system(\"cp {0} {1}\".format(impath, fnamepath + i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yamlinput = \"\"\"\n",
    "            # YOLOv5 🚀 by Ultralytics, AGPL-3.0 license\n",
    "            # COCO128 dataset https://www.kaggle.com/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics\n",
    "            # Example usage: python train.py --data coco128.yaml\n",
    "            # parent\n",
    "            # ├── yolov5\n",
    "            # └── datasets\n",
    "            #     └── coco128  ← downloads here (7 MB)\n",
    "\n",
    "            # Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
    "            path: '/mnt/batch/tasks/shared/LS_root/mounts/clusters/avanplatinga-gpu-nv6/code/Users/AVanPlantinga/OCR/yolov5/'# dataset root dir\n",
    "            train: images # train images (relative to 'path') 128 images\n",
    "            val: images # val images (relative to 'path') 128 images\n",
    "            test: # test images (optional)\n",
    "            # Classes\n",
    "            names:\n",
    "              0: class1 #\n",
    "            \"\"\"\n",
    "\n",
    "f = open(\"yolov5/newyolo_conf.yml\", \"w\")\n",
    "f.close()\n",
    "f = open(\"yolov5/newyolo_conf.yml\", \"a\")\n",
    "f.write(yamlinput)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.23.4\n",
    "!pip uninstall comet-ml -y\n",
    "#import numpy as np\n",
    "#!pip install gitpython\n",
    "#!pip uninstall protobuf -y\n",
    "#!pip install protobuf \n",
    "#!tensorboard --logdir yolov5/runs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLOv5s on COCO128 for 3 epochs\n",
    "#!tensorboard --logdir yolov5/runs/train\n",
    "#!git config --global --add safe.directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/avanplatinga-gpu-nv6/code/Users/AVanPlantinga/OCR/yolov5\n",
    "!python yolov5/train.py --img 1568 --batch 8 --epochs 10 --data yolov5/newyolo_conf.yml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/detect.py --weights yolov5/runs/train/exp5/weights/best.pt --img 1568 --conf 0.1 --source Florida"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
